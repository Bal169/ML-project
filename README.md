# Fake-News-Classification

## Problem Statement
In today's information age, we consume news from various sources, and distinguishing between genuine and fake news can be challenging. The goal of this project is to develop a model that predicts the authenticity of news articles, helping users identify trustworthy news sources.

## Project Flow

### 1. Problem Statement
- Description of the problem: Identifying fake news articles among various sources.

### 2. Data Gathering
- Using the python code to extract first 1000 rows of "https://zenodo.org/records/4561253/files/WELFake_Dataset.csv" from this data set

### 3. Data Preprocessing
- Techniques used for data cleaning and preparation, including:
  - Tokenization
  - Converting text to lowercase
  - Removing stopwords
  - Lemmatization / Stemming

### 4. Vectorization
- Converting text data into numerical format:
  - Bag Of Words (CountVectorizer)
  - TF-IDF (Term Frequency-Inverse Document Frequency)

### 5. Model Building
- Building the predictive model:
  - Model initialization and selection
  - Training and testing the model

### 6. Model Evaluation
- Assessing model performance:
  - Accuracy Score
  - Confusion Matrix
  - Classification Report

### 7. Model Deployment
- Details on how to deploy the trained model for real-world use.

### 8. Prediction on Client Data
- Instructions for using the model to make predictions on new data.

## Tech Stack Used
- Python: Programming language used for development.
- NLP (Natural Language Processing): Techniques used for text analysis.
- Machine Learning Algorithms: Algorithms used for modeling and prediction.
- Prompt engineering

## Acknowledgments
-I have taken the help of Youtube,Chatgpt, Google Bard etc.

Feel free to expand on each section and add relevant details to make your project's README more informative and user-friendly.



